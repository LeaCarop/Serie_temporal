{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parte2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7OXSdYnp4NdasJBU3Ch/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeaCarop/Serie_temporal/blob/main/Parte2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRIMERA PARTE \n",
        "\n",
        "## RED NEURONAL CON **UNA VARIABLE**"
      ],
      "metadata": {
        "id": "Q0vCfOktVtx-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ii7vMHFrVmyf"
      },
      "outputs": [],
      "source": [
        "# IMPORTAR LIBRERÍAS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline \n",
        "plt.rcParams['figure.figsize'] = (16, 9) # para personalizar la dimensión de todos los gráficos\n",
        "plt.style.use('fast') # para crear un estilo personalizado\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CARGAR ARCHIVO CSV CON LOS DATOS\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbagnato/machine-learning/master/time_series.csv\"\n",
        "df = pd.read_csv(url, parse_dates=[0], header=None, index_col=0, squeeze=True, names=['fecha','unidades'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmIv1T3eWIap",
        "outputId": "327cdddd-0d40-45a1-e14e-a5945c2292f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fecha\n",
              "2017-01-02    236\n",
              "2017-01-03    237\n",
              "2017-01-04    290\n",
              "2017-01-05    221\n",
              "2017-01-07    128\n",
              "Name: unidades, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRONÓSTICO DE VENTAS DIARIAS CON RED NEURONAL"
      ],
      "metadata": {
        "id": "hf9J_jIQWZl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PASOS=7\n",
        "\n",
        "# convertir series en aprendizaje supervisado\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # secuencia de entrada (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # secuencia de pronóstico (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # poner todo junto\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # eliminar filas con valores NaN\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        " \n",
        "# cargar datos\n",
        "values = df.values\n",
        "# asegúrese de que todos los datos sean flotantes\n",
        "values = values.astype('float32')\n",
        "# normalizar variable\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
        "scaled = scaler.fit_transform(values)\n",
        "# enmarcar como aprendizaje supervisado\n",
        "reframed = series_to_supervised(scaled, PASOS, 1)\n",
        "reframed.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PpB4bsdNX2rl",
        "outputId": "e72d440a-a3ab-4b8d-ea18-2321ce6b1fbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    var1(t-7)  var1(t-6)  var1(t-5)  var1(t-4)  var1(t-3)  var1(t-2)  \\\n",
              "7   -0.314815  -0.311111  -0.114815  -0.370370  -0.714815  -0.103704   \n",
              "8   -0.311111  -0.114815  -0.370370  -0.714815  -0.103704  -0.225926   \n",
              "9   -0.114815  -0.370370  -0.714815  -0.103704  -0.225926  -0.433333   \n",
              "10  -0.370370  -0.714815  -0.103704  -0.225926  -0.433333  -0.607407   \n",
              "11  -0.714815  -0.103704  -0.225926  -0.433333  -0.607407  -0.522222   \n",
              "\n",
              "    var1(t-1)   var1(t)  \n",
              "7   -0.225926 -0.433333  \n",
              "8   -0.433333 -0.607407  \n",
              "9   -0.607407 -0.522222  \n",
              "10  -0.522222 -0.644444  \n",
              "11  -0.644444 -0.344444  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62dee2e9-f6e0-4909-99e7-acf94deb277f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-7)</th>\n",
              "      <th>var1(t-6)</th>\n",
              "      <th>var1(t-5)</th>\n",
              "      <th>var1(t-4)</th>\n",
              "      <th>var1(t-3)</th>\n",
              "      <th>var1(t-2)</th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.314815</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.311111</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>-0.644444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>-0.644444</td>\n",
              "      <td>-0.344444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62dee2e9-f6e0-4909-99e7-acf94deb277f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62dee2e9-f6e0-4909-99e7-acf94deb277f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62dee2e9-f6e0-4909-99e7-acf94deb277f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIVIDIR DATASET EN TRAIN Y TEST\n",
        "\n",
        "values = reframed.values\n",
        "n_train_days = 315+289 - (30+PASOS)\n",
        "train = values[:n_train_days, :]\n",
        "test = values[n_train_days:, :]\n",
        "# split into input and outputs\n",
        "x_train, y_train = train[:, :-1], train[:, -1]\n",
        "x_val, y_val = test[:, :-1], test[:, -1]\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
        "x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
        "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I07BvkETX7j4",
        "outputId": "ed6d733b-cbbb-4362-f269-e91c3c1a9b7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(567, 1, 7) (567,) (30, 1, 7) (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARQUITECTURA DE LA RED NEURONAL\n",
        "   # agrego capa oculta con 4 neuronas\n",
        "   # cambio de oprimizador Adam a Nadam\n",
        "\n",
        "def crear_modeloFF():\n",
        "    model = Sequential() \n",
        "    model.add(Dense(PASOS, input_shape=(1,PASOS),activation='tanh'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4, input_shape=(1,PASOS),activation='tanh'))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(loss='mean_absolute_error', optimizer='Nadam', metrics=[\"mse\"])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "3slNXs1VX-u3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta primera arquitectura de red neuronal he realizado algunos cambios en comparación a la que veíamos en la Parte 1:\n",
        "* Agrego capa oculta con 4 neuronas, manteniendo igual input_shape y la función de activación (la razón principal de mantenerla es porque los valores se están escalando entre -1 y 1. Usar otra función de activación significa que todos los valores inferiores a 0 los tiene en cuenta como 0).\n",
        "* Cambio de optimizador de Adam a **Nadam**. Es muy parecido a Adam pero converge mejor. "
      ],
      "metadata": {
        "id": "EUC4Fll9bTAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTRENAMIENTO\n",
        "  # mantengo número de épocas\n",
        "\n",
        "EPOCHS=40\n",
        " \n",
        "model = crear_modeloFF()\n",
        " \n",
        "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlyBMoCgaw9h",
        "outputId": "53357e09-ee1f-4e93-92aa-a4cb20303b8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1, 7)              56        \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 93\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "81/81 [==============================] - 1s 5ms/step - loss: 0.2102 - mse: 0.0763 - val_loss: 0.1591 - val_mse: 0.0407\n",
            "Epoch 2/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1903 - mse: 0.0642 - val_loss: 0.1482 - val_mse: 0.0422\n",
            "Epoch 3/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1831 - mse: 0.0613 - val_loss: 0.1430 - val_mse: 0.0388\n",
            "Epoch 4/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1788 - mse: 0.0592 - val_loss: 0.1443 - val_mse: 0.0395\n",
            "Epoch 5/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1766 - mse: 0.0582 - val_loss: 0.1459 - val_mse: 0.0399\n",
            "Epoch 6/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1753 - mse: 0.0578 - val_loss: 0.1402 - val_mse: 0.0366\n",
            "Epoch 7/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1736 - mse: 0.0568 - val_loss: 0.1424 - val_mse: 0.0379\n",
            "Epoch 8/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1733 - mse: 0.0565 - val_loss: 0.1395 - val_mse: 0.0363\n",
            "Epoch 9/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1723 - mse: 0.0564 - val_loss: 0.1429 - val_mse: 0.0378\n",
            "Epoch 10/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1722 - mse: 0.0564 - val_loss: 0.1423 - val_mse: 0.0374\n",
            "Epoch 11/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1718 - mse: 0.0557 - val_loss: 0.1399 - val_mse: 0.0362\n",
            "Epoch 12/40\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1715 - mse: 0.0559 - val_loss: 0.1403 - val_mse: 0.0364\n",
            "Epoch 13/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1713 - mse: 0.0559 - val_loss: 0.1394 - val_mse: 0.0356\n",
            "Epoch 14/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1721 - mse: 0.0564 - val_loss: 0.1405 - val_mse: 0.0352\n",
            "Epoch 15/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1713 - mse: 0.0562 - val_loss: 0.1407 - val_mse: 0.0351\n",
            "Epoch 16/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1703 - mse: 0.0551 - val_loss: 0.1392 - val_mse: 0.0352\n",
            "Epoch 17/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1702 - mse: 0.0559 - val_loss: 0.1399 - val_mse: 0.0351\n",
            "Epoch 18/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1702 - mse: 0.0554 - val_loss: 0.1401 - val_mse: 0.0360\n",
            "Epoch 19/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1701 - mse: 0.0556 - val_loss: 0.1396 - val_mse: 0.0357\n",
            "Epoch 20/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1695 - mse: 0.0557 - val_loss: 0.1460 - val_mse: 0.0382\n",
            "Epoch 21/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1698 - mse: 0.0555 - val_loss: 0.1418 - val_mse: 0.0350\n",
            "Epoch 22/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1699 - mse: 0.0554 - val_loss: 0.1429 - val_mse: 0.0370\n",
            "Epoch 23/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1693 - mse: 0.0550 - val_loss: 0.1409 - val_mse: 0.0363\n",
            "Epoch 24/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1692 - mse: 0.0553 - val_loss: 0.1393 - val_mse: 0.0353\n",
            "Epoch 25/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1691 - mse: 0.0548 - val_loss: 0.1442 - val_mse: 0.0349\n",
            "Epoch 26/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1695 - mse: 0.0553 - val_loss: 0.1434 - val_mse: 0.0371\n",
            "Epoch 27/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1692 - mse: 0.0554 - val_loss: 0.1396 - val_mse: 0.0357\n",
            "Epoch 28/40\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1693 - mse: 0.0554 - val_loss: 0.1417 - val_mse: 0.0346\n",
            "Epoch 29/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1692 - mse: 0.0552 - val_loss: 0.1411 - val_mse: 0.0362\n",
            "Epoch 30/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1684 - mse: 0.0549 - val_loss: 0.1462 - val_mse: 0.0380\n",
            "Epoch 31/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1683 - mse: 0.0549 - val_loss: 0.1433 - val_mse: 0.0370\n",
            "Epoch 32/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1683 - mse: 0.0546 - val_loss: 0.1425 - val_mse: 0.0367\n",
            "Epoch 33/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1684 - mse: 0.0548 - val_loss: 0.1392 - val_mse: 0.0346\n",
            "Epoch 34/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1684 - mse: 0.0549 - val_loss: 0.1405 - val_mse: 0.0356\n",
            "Epoch 35/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1678 - mse: 0.0545 - val_loss: 0.1394 - val_mse: 0.0346\n",
            "Epoch 36/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1677 - mse: 0.0547 - val_loss: 0.1404 - val_mse: 0.0344\n",
            "Epoch 37/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1679 - mse: 0.0547 - val_loss: 0.1407 - val_mse: 0.0355\n",
            "Epoch 38/40\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1671 - mse: 0.0543 - val_loss: 0.1417 - val_mse: 0.0360\n",
            "Epoch 39/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1680 - mse: 0.0551 - val_loss: 0.1415 - val_mse: 0.0359\n",
            "Epoch 40/40\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1671 - mse: 0.0540 - val_loss: 0.1449 - val_mse: 0.0375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manteniendo el mismo número de épocas vemos como logramos bajar levemente los valores de loss y mse."
      ],
      "metadata": {
        "id": "gkY6y2-Xchou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTRENAMIENTO\n",
        "  # aumento el número de épocas\n",
        "\n",
        "EPOCHS=60\n",
        " \n",
        "model = crear_modeloFF()\n",
        " \n",
        "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fDDDA77bD8G",
        "outputId": "ea5cfc5a-dd8f-4620-d71a-d8dc751c13f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 1, 7)              56        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 93\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "81/81 [==============================] - 1s 4ms/step - loss: 0.2741 - mse: 0.1253 - val_loss: 0.2114 - val_mse: 0.0776\n",
            "Epoch 2/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.2102 - mse: 0.0767 - val_loss: 0.1607 - val_mse: 0.0552\n",
            "Epoch 3/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1869 - mse: 0.0628 - val_loss: 0.1533 - val_mse: 0.0476\n",
            "Epoch 4/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1770 - mse: 0.0574 - val_loss: 0.1465 - val_mse: 0.0409\n",
            "Epoch 5/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1733 - mse: 0.0551 - val_loss: 0.1442 - val_mse: 0.0398\n",
            "Epoch 6/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1699 - mse: 0.0536 - val_loss: 0.1436 - val_mse: 0.0392\n",
            "Epoch 7/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1689 - mse: 0.0533 - val_loss: 0.1443 - val_mse: 0.0391\n",
            "Epoch 8/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1662 - mse: 0.0514 - val_loss: 0.1479 - val_mse: 0.0404\n",
            "Epoch 9/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1672 - mse: 0.0526 - val_loss: 0.1449 - val_mse: 0.0381\n",
            "Epoch 10/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1659 - mse: 0.0520 - val_loss: 0.1479 - val_mse: 0.0394\n",
            "Epoch 11/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1662 - mse: 0.0517 - val_loss: 0.1441 - val_mse: 0.0381\n",
            "Epoch 12/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1648 - mse: 0.0517 - val_loss: 0.1444 - val_mse: 0.0378\n",
            "Epoch 13/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1651 - mse: 0.0518 - val_loss: 0.1448 - val_mse: 0.0377\n",
            "Epoch 14/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1646 - mse: 0.0517 - val_loss: 0.1469 - val_mse: 0.0375\n",
            "Epoch 15/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1647 - mse: 0.0510 - val_loss: 0.1472 - val_mse: 0.0397\n",
            "Epoch 16/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1645 - mse: 0.0509 - val_loss: 0.1464 - val_mse: 0.0378\n",
            "Epoch 17/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1644 - mse: 0.0511 - val_loss: 0.1440 - val_mse: 0.0383\n",
            "Epoch 18/60\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 0.1642 - mse: 0.0512 - val_loss: 0.1447 - val_mse: 0.0380\n",
            "Epoch 19/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1634 - mse: 0.0502 - val_loss: 0.1509 - val_mse: 0.0378\n",
            "Epoch 20/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1638 - mse: 0.0506 - val_loss: 0.1444 - val_mse: 0.0385\n",
            "Epoch 21/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1639 - mse: 0.0508 - val_loss: 0.1449 - val_mse: 0.0384\n",
            "Epoch 22/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1631 - mse: 0.0509 - val_loss: 0.1495 - val_mse: 0.0378\n",
            "Epoch 23/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1641 - mse: 0.0508 - val_loss: 0.1488 - val_mse: 0.0379\n",
            "Epoch 24/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1617 - mse: 0.0508 - val_loss: 0.1455 - val_mse: 0.0387\n",
            "Epoch 25/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1629 - mse: 0.0501 - val_loss: 0.1457 - val_mse: 0.0398\n",
            "Epoch 26/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1633 - mse: 0.0509 - val_loss: 0.1493 - val_mse: 0.0381\n",
            "Epoch 27/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1628 - mse: 0.0496 - val_loss: 0.1454 - val_mse: 0.0385\n",
            "Epoch 28/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1619 - mse: 0.0498 - val_loss: 0.1456 - val_mse: 0.0384\n",
            "Epoch 29/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1630 - mse: 0.0499 - val_loss: 0.1469 - val_mse: 0.0381\n",
            "Epoch 30/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1626 - mse: 0.0496 - val_loss: 0.1494 - val_mse: 0.0384\n",
            "Epoch 31/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1626 - mse: 0.0502 - val_loss: 0.1468 - val_mse: 0.0387\n",
            "Epoch 32/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1614 - mse: 0.0494 - val_loss: 0.1503 - val_mse: 0.0411\n",
            "Epoch 33/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1621 - mse: 0.0495 - val_loss: 0.1502 - val_mse: 0.0381\n",
            "Epoch 34/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1617 - mse: 0.0500 - val_loss: 0.1489 - val_mse: 0.0379\n",
            "Epoch 35/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1624 - mse: 0.0501 - val_loss: 0.1452 - val_mse: 0.0387\n",
            "Epoch 36/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1611 - mse: 0.0500 - val_loss: 0.1471 - val_mse: 0.0392\n",
            "Epoch 37/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1617 - mse: 0.0495 - val_loss: 0.1495 - val_mse: 0.0381\n",
            "Epoch 38/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1612 - mse: 0.0492 - val_loss: 0.1489 - val_mse: 0.0379\n",
            "Epoch 39/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1612 - mse: 0.0494 - val_loss: 0.1466 - val_mse: 0.0401\n",
            "Epoch 40/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1613 - mse: 0.0495 - val_loss: 0.1544 - val_mse: 0.0385\n",
            "Epoch 41/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1613 - mse: 0.0494 - val_loss: 0.1476 - val_mse: 0.0378\n",
            "Epoch 42/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1601 - mse: 0.0492 - val_loss: 0.1521 - val_mse: 0.0381\n",
            "Epoch 43/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1607 - mse: 0.0492 - val_loss: 0.1487 - val_mse: 0.0378\n",
            "Epoch 44/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1609 - mse: 0.0490 - val_loss: 0.1454 - val_mse: 0.0380\n",
            "Epoch 45/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1597 - mse: 0.0492 - val_loss: 0.1496 - val_mse: 0.0379\n",
            "Epoch 46/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1603 - mse: 0.0487 - val_loss: 0.1565 - val_mse: 0.0390\n",
            "Epoch 47/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1600 - mse: 0.0489 - val_loss: 0.1475 - val_mse: 0.0382\n",
            "Epoch 48/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1607 - mse: 0.0487 - val_loss: 0.1499 - val_mse: 0.0381\n",
            "Epoch 49/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1602 - mse: 0.0492 - val_loss: 0.1482 - val_mse: 0.0383\n",
            "Epoch 50/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1599 - mse: 0.0490 - val_loss: 0.1473 - val_mse: 0.0379\n",
            "Epoch 51/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1593 - mse: 0.0489 - val_loss: 0.1504 - val_mse: 0.0381\n",
            "Epoch 52/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1596 - mse: 0.0489 - val_loss: 0.1517 - val_mse: 0.0382\n",
            "Epoch 53/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1591 - mse: 0.0490 - val_loss: 0.1503 - val_mse: 0.0379\n",
            "Epoch 54/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1600 - mse: 0.0487 - val_loss: 0.1478 - val_mse: 0.0378\n",
            "Epoch 55/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1597 - mse: 0.0487 - val_loss: 0.1500 - val_mse: 0.0379\n",
            "Epoch 56/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1586 - mse: 0.0486 - val_loss: 0.1572 - val_mse: 0.0390\n",
            "Epoch 57/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1596 - mse: 0.0491 - val_loss: 0.1528 - val_mse: 0.0385\n",
            "Epoch 58/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1594 - mse: 0.0487 - val_loss: 0.1484 - val_mse: 0.0377\n",
            "Epoch 59/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1593 - mse: 0.0487 - val_loss: 0.1506 - val_mse: 0.0382\n",
            "Epoch 60/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1586 - mse: 0.0483 - val_loss: 0.1473 - val_mse: 0.0378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si añado más epocas logro disminuir aún más los valores de loss y mse, pero aún no son inferiores a la red neuronal con múltiples variables. \n",
        "\n",
        "Probaré nuevamente con la misma arquitectura pero cambiando el optimizador. He usado **SGD, AdaGrad y AdaMax** pero el que ofrece unos valores más bajos es **RMSProp.** Sin embargo, este modelo tiene mucho overfitting, por lo que seguiré trabajando con el anterior. "
      ],
      "metadata": {
        "id": "Vhb1z3iSczbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ARQUITECTURA DE LA RED NEURONAL\n",
        "  # mantengo la nueva capa oculta\n",
        "  # uso optimizador RMSprop\n",
        "\n",
        "def crear_modeloFF():\n",
        "    model1 = Sequential() \n",
        "    model1.add(Dense(PASOS, input_shape=(1,PASOS),activation='tanh'))\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dense(4, input_shape=(1,PASOS),activation='tanh'))\n",
        "    model1.add(Dense(1, activation='tanh'))\n",
        "    model1.compile(loss='mean_absolute_error', optimizer='RMSprop', metrics=[\"mse\"])\n",
        "    model1.summary()\n",
        "    return model1"
      ],
      "metadata": {
        "id": "A-FHYE24dN9s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTRENAMIENTO\n",
        "\n",
        "EPOCHS=60\n",
        " \n",
        "model1 = crear_modeloFF()\n",
        " \n",
        "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_TbiB5hdXY9",
        "outputId": "17da48a3-36f4-4ad0-be74-addee5431e9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1, 7)              56        \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 93\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1592 - mse: 0.0479 - val_loss: 0.1461 - val_mse: 0.0362\n",
            "Epoch 2/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1586 - mse: 0.0477 - val_loss: 0.1480 - val_mse: 0.0359\n",
            "Epoch 3/60\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.1584 - mse: 0.0476 - val_loss: 0.1511 - val_mse: 0.0364\n",
            "Epoch 4/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1585 - mse: 0.0475 - val_loss: 0.1481 - val_mse: 0.0360\n",
            "Epoch 5/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1586 - mse: 0.0477 - val_loss: 0.1524 - val_mse: 0.0367\n",
            "Epoch 6/60\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.1579 - mse: 0.0474 - val_loss: 0.1447 - val_mse: 0.0359\n",
            "Epoch 7/60\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.1585 - mse: 0.0477 - val_loss: 0.1463 - val_mse: 0.0358\n",
            "Epoch 8/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1581 - mse: 0.0474 - val_loss: 0.1448 - val_mse: 0.0361\n",
            "Epoch 9/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1581 - mse: 0.0471 - val_loss: 0.1505 - val_mse: 0.0362\n",
            "Epoch 10/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1568 - mse: 0.0468 - val_loss: 0.1391 - val_mse: 0.0358\n",
            "Epoch 11/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1581 - mse: 0.0472 - val_loss: 0.1470 - val_mse: 0.0355\n",
            "Epoch 12/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1572 - mse: 0.0470 - val_loss: 0.1453 - val_mse: 0.0353\n",
            "Epoch 13/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1573 - mse: 0.0472 - val_loss: 0.1445 - val_mse: 0.0354\n",
            "Epoch 14/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1572 - mse: 0.0467 - val_loss: 0.1469 - val_mse: 0.0354\n",
            "Epoch 15/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1572 - mse: 0.0472 - val_loss: 0.1491 - val_mse: 0.0357\n",
            "Epoch 16/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1570 - mse: 0.0469 - val_loss: 0.1427 - val_mse: 0.0360\n",
            "Epoch 17/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1567 - mse: 0.0467 - val_loss: 0.1465 - val_mse: 0.0356\n",
            "Epoch 18/60\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 0.1565 - mse: 0.0465 - val_loss: 0.1463 - val_mse: 0.0354\n",
            "Epoch 19/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1569 - mse: 0.0469 - val_loss: 0.1494 - val_mse: 0.0362\n",
            "Epoch 20/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1567 - mse: 0.0469 - val_loss: 0.1440 - val_mse: 0.0357\n",
            "Epoch 21/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1562 - mse: 0.0466 - val_loss: 0.1468 - val_mse: 0.0354\n",
            "Epoch 22/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1558 - mse: 0.0464 - val_loss: 0.1398 - val_mse: 0.0358\n",
            "Epoch 23/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1561 - mse: 0.0464 - val_loss: 0.1498 - val_mse: 0.0361\n",
            "Epoch 24/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1564 - mse: 0.0462 - val_loss: 0.1473 - val_mse: 0.0358\n",
            "Epoch 25/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1561 - mse: 0.0465 - val_loss: 0.1450 - val_mse: 0.0350\n",
            "Epoch 26/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1558 - mse: 0.0463 - val_loss: 0.1451 - val_mse: 0.0353\n",
            "Epoch 27/60\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 0.1560 - mse: 0.0462 - val_loss: 0.1448 - val_mse: 0.0351\n",
            "Epoch 28/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1558 - mse: 0.0462 - val_loss: 0.1437 - val_mse: 0.0349\n",
            "Epoch 29/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1554 - mse: 0.0462 - val_loss: 0.1480 - val_mse: 0.0355\n",
            "Epoch 30/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1552 - mse: 0.0460 - val_loss: 0.1459 - val_mse: 0.0352\n",
            "Epoch 31/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1555 - mse: 0.0461 - val_loss: 0.1482 - val_mse: 0.0355\n",
            "Epoch 32/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1556 - mse: 0.0462 - val_loss: 0.1419 - val_mse: 0.0350\n",
            "Epoch 33/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1548 - mse: 0.0458 - val_loss: 0.1441 - val_mse: 0.0348\n",
            "Epoch 34/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1544 - mse: 0.0460 - val_loss: 0.1407 - val_mse: 0.0354\n",
            "Epoch 35/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1549 - mse: 0.0461 - val_loss: 0.1400 - val_mse: 0.0345\n",
            "Epoch 36/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1547 - mse: 0.0456 - val_loss: 0.1369 - val_mse: 0.0345\n",
            "Epoch 37/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1545 - mse: 0.0460 - val_loss: 0.1454 - val_mse: 0.0351\n",
            "Epoch 38/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1541 - mse: 0.0456 - val_loss: 0.1401 - val_mse: 0.0351\n",
            "Epoch 39/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1542 - mse: 0.0458 - val_loss: 0.1447 - val_mse: 0.0355\n",
            "Epoch 40/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1535 - mse: 0.0454 - val_loss: 0.1443 - val_mse: 0.0345\n",
            "Epoch 41/60\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.1540 - mse: 0.0457 - val_loss: 0.1417 - val_mse: 0.0346\n",
            "Epoch 42/60\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 0.1538 - mse: 0.0455 - val_loss: 0.1408 - val_mse: 0.0342\n",
            "Epoch 43/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1544 - mse: 0.0456 - val_loss: 0.1422 - val_mse: 0.0348\n",
            "Epoch 44/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1535 - mse: 0.0451 - val_loss: 0.1407 - val_mse: 0.0348\n",
            "Epoch 45/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1542 - mse: 0.0458 - val_loss: 0.1459 - val_mse: 0.0352\n",
            "Epoch 46/60\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.1533 - mse: 0.0451 - val_loss: 0.1425 - val_mse: 0.0344\n",
            "Epoch 47/60\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.1531 - mse: 0.0455 - val_loss: 0.1452 - val_mse: 0.0351\n",
            "Epoch 48/60\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 0.1531 - mse: 0.0451 - val_loss: 0.1431 - val_mse: 0.0349\n",
            "Epoch 49/60\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.1530 - mse: 0.0451 - val_loss: 0.1401 - val_mse: 0.0348\n",
            "Epoch 50/60\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.1528 - mse: 0.0451 - val_loss: 0.1433 - val_mse: 0.0348\n",
            "Epoch 51/60\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.1525 - mse: 0.0448 - val_loss: 0.1357 - val_mse: 0.0344\n",
            "Epoch 52/60\n",
            "81/81 [==============================] - 1s 10ms/step - loss: 0.1533 - mse: 0.0454 - val_loss: 0.1451 - val_mse: 0.0352\n",
            "Epoch 53/60\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 0.1519 - mse: 0.0448 - val_loss: 0.1395 - val_mse: 0.0347\n",
            "Epoch 54/60\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.1524 - mse: 0.0448 - val_loss: 0.1435 - val_mse: 0.0348\n",
            "Epoch 55/60\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.1528 - mse: 0.0453 - val_loss: 0.1435 - val_mse: 0.0349\n",
            "Epoch 56/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1524 - mse: 0.0448 - val_loss: 0.1439 - val_mse: 0.0350\n",
            "Epoch 57/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1520 - mse: 0.0448 - val_loss: 0.1451 - val_mse: 0.0352\n",
            "Epoch 58/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1523 - mse: 0.0447 - val_loss: 0.1407 - val_mse: 0.0348\n",
            "Epoch 59/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1523 - mse: 0.0448 - val_loss: 0.1422 - val_mse: 0.0346\n",
            "Epoch 60/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1515 - mse: 0.0447 - val_loss: 0.1399 - val_mse: 0.0353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Representándolo gráficamente este modelo comete mucho overfitting."
      ],
      "metadata": {
        "id": "VFlVk64XH2y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICCIÓN\n",
        "\n",
        "results=model.predict(x_val)\n",
        "plt.scatter(range(len(y_val)),y_val,c='g', label= 'y_val')\n",
        "plt.scatter(range(len(results)),results,c='r', label = 'results')\n",
        "plt.title('validate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "jqC-oCskk17Y",
        "outputId": "232d19ca-a142-4187-c653-fc90aee19e80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "plt.title('loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.title('validate loss')\n",
        "plt.legend(loc=\"right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4Yyv0cJdyGYi",
        "outputId": "f02ebf6c-1daf-49af-912d-00882028e938"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEGUNDA PARTE\n",
        "\n",
        "### RED NEURONAL CON **MÚLTIPLES VARIABLES**"
      ],
      "metadata": {
        "id": "M9zQDMtV4OLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/jbagnato/machine-learning/master/time_series.csv\"\n",
        "df = pd.read_csv(url, parse_dates=[0], header=None, index_col=0, names=['fecha','unidades'])\n",
        "\n",
        "# CARGAR DATOS CATEGÓRICOS \n",
        "\n",
        "df['weekday']=[x.weekday() for x in df.index]\n",
        "df['month']=[x.month for x in df.index]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "u0YknQBd4MXj",
        "outputId": "8df0084a-95c2-4e2c-b1dc-f4774ebb3238"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            unidades  weekday  month\n",
              "fecha                               \n",
              "2017-01-02       236        0      1\n",
              "2017-01-03       237        1      1\n",
              "2017-01-04       290        2      1\n",
              "2017-01-05       221        3      1\n",
              "2017-01-07       128        5      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90c08f93-95b4-4880-9482-d4baba3d13d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unidades</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fecha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-02</th>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03</th>\n",
              "      <td>237</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04</th>\n",
              "      <td>290</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-05</th>\n",
              "      <td>221</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-07</th>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90c08f93-95b4-4880-9482-d4baba3d13d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90c08f93-95b4-4880-9482-d4baba3d13d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90c08f93-95b4-4880-9482-d4baba3d13d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROCESADO DE DATOS\n",
        "\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "metadata": {
        "id": "NCEDeejB4oqC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PASOS=7\n",
        "\n",
        "# load dataset\n",
        "values = df['unidades'].values\n",
        "\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
        "scaled = scaler.fit_transform(values)\n",
        "\n",
        "df['scaled'] = scaled\n",
        "scaledMerge=df.drop('unidades',axis=1)\n",
        "#print(scaledMerge.values)\n",
        "\n",
        "# frame as supervised learning\n",
        "reframed = series_to_supervised(scaledMerge, PASOS, 1)\n",
        "reframed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "ZXFWlCpt4tLc",
        "outputId": "0d681c31-bfff-4d02-f904-1bd5ab0b2d58"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            var1(t-7)  var2(t-7)  var3(t-7)  var1(t-6)  var2(t-6)  var3(t-6)  \\\n",
              "fecha                                                                          \n",
              "2017-01-11        0.0        1.0  -0.314815        1.0        1.0  -0.311111   \n",
              "2017-01-12        1.0        1.0  -0.311111        2.0        1.0  -0.114815   \n",
              "2017-01-13        2.0        1.0  -0.114815        3.0        1.0  -0.370370   \n",
              "2017-01-14        3.0        1.0  -0.370370        5.0        1.0  -0.714815   \n",
              "2017-01-16        5.0        1.0  -0.714815        0.0        1.0  -0.103704   \n",
              "\n",
              "            var1(t-5)  var2(t-5)  var3(t-5)  var1(t-4)  ...  var3(t-3)  \\\n",
              "fecha                                                   ...              \n",
              "2017-01-11        2.0        1.0  -0.114815        3.0  ...  -0.714815   \n",
              "2017-01-12        3.0        1.0  -0.370370        5.0  ...  -0.103704   \n",
              "2017-01-13        5.0        1.0  -0.714815        0.0  ...  -0.225926   \n",
              "2017-01-14        0.0        1.0  -0.103704        1.0  ...  -0.433333   \n",
              "2017-01-16        1.0        1.0  -0.225926        2.0  ...  -0.607407   \n",
              "\n",
              "            var1(t-2)  var2(t-2)  var3(t-2)  var1(t-1)  var2(t-1)  var3(t-1)  \\\n",
              "fecha                                                                          \n",
              "2017-01-11        0.0        1.0  -0.103704        1.0        1.0  -0.225926   \n",
              "2017-01-12        1.0        1.0  -0.225926        2.0        1.0  -0.433333   \n",
              "2017-01-13        2.0        1.0  -0.433333        3.0        1.0  -0.607407   \n",
              "2017-01-14        3.0        1.0  -0.607407        4.0        1.0  -0.522222   \n",
              "2017-01-16        4.0        1.0  -0.522222        5.0        1.0  -0.644444   \n",
              "\n",
              "            var1(t)  var2(t)   var3(t)  \n",
              "fecha                                   \n",
              "2017-01-11        2        1 -0.433333  \n",
              "2017-01-12        3        1 -0.607407  \n",
              "2017-01-13        4        1 -0.522222  \n",
              "2017-01-14        5        1 -0.644444  \n",
              "2017-01-16        0        1 -0.344444  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67c2bc3f-0498-4eaf-95f0-39e1a2473fff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-7)</th>\n",
              "      <th>var2(t-7)</th>\n",
              "      <th>var3(t-7)</th>\n",
              "      <th>var1(t-6)</th>\n",
              "      <th>var2(t-6)</th>\n",
              "      <th>var3(t-6)</th>\n",
              "      <th>var1(t-5)</th>\n",
              "      <th>var2(t-5)</th>\n",
              "      <th>var3(t-5)</th>\n",
              "      <th>var1(t-4)</th>\n",
              "      <th>...</th>\n",
              "      <th>var3(t-3)</th>\n",
              "      <th>var1(t-2)</th>\n",
              "      <th>var2(t-2)</th>\n",
              "      <th>var3(t-2)</th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var2(t-1)</th>\n",
              "      <th>var3(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "      <th>var2(t)</th>\n",
              "      <th>var3(t)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fecha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.314815</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.607407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-13</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.522222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-14</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.644444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-16</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.644444</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.344444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67c2bc3f-0498-4eaf-95f0-39e1a2473fff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67c2bc3f-0498-4eaf-95f0-39e1a2473fff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67c2bc3f-0498-4eaf-95f0-39e1a2473fff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newReframed=reframed.drop(['var1(t)','var2(t)'],axis=1)  # se eliminan las variables var1 y var2\n",
        "print(newReframed.shape)\n",
        "newReframed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lif7W-bb4ovM",
        "outputId": "188bfa4f-f09d-4782-f1ef-3bdc450c45c5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(597, 22)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            var1(t-7)  var2(t-7)  var3(t-7)  var1(t-6)  var2(t-6)  var3(t-6)  \\\n",
              "fecha                                                                          \n",
              "2017-01-11        0.0        1.0  -0.314815        1.0        1.0  -0.311111   \n",
              "2017-01-12        1.0        1.0  -0.311111        2.0        1.0  -0.114815   \n",
              "2017-01-13        2.0        1.0  -0.114815        3.0        1.0  -0.370370   \n",
              "2017-01-14        3.0        1.0  -0.370370        5.0        1.0  -0.714815   \n",
              "2017-01-16        5.0        1.0  -0.714815        0.0        1.0  -0.103704   \n",
              "\n",
              "            var1(t-5)  var2(t-5)  var3(t-5)  var1(t-4)  ...  var1(t-3)  \\\n",
              "fecha                                                   ...              \n",
              "2017-01-11        2.0        1.0  -0.114815        3.0  ...        5.0   \n",
              "2017-01-12        3.0        1.0  -0.370370        5.0  ...        0.0   \n",
              "2017-01-13        5.0        1.0  -0.714815        0.0  ...        1.0   \n",
              "2017-01-14        0.0        1.0  -0.103704        1.0  ...        2.0   \n",
              "2017-01-16        1.0        1.0  -0.225926        2.0  ...        3.0   \n",
              "\n",
              "            var2(t-3)  var3(t-3)  var1(t-2)  var2(t-2)  var3(t-2)  var1(t-1)  \\\n",
              "fecha                                                                          \n",
              "2017-01-11        1.0  -0.714815        0.0        1.0  -0.103704        1.0   \n",
              "2017-01-12        1.0  -0.103704        1.0        1.0  -0.225926        2.0   \n",
              "2017-01-13        1.0  -0.225926        2.0        1.0  -0.433333        3.0   \n",
              "2017-01-14        1.0  -0.433333        3.0        1.0  -0.607407        4.0   \n",
              "2017-01-16        1.0  -0.607407        4.0        1.0  -0.522222        5.0   \n",
              "\n",
              "            var2(t-1)  var3(t-1)   var3(t)  \n",
              "fecha                                       \n",
              "2017-01-11        1.0  -0.225926 -0.433333  \n",
              "2017-01-12        1.0  -0.433333 -0.607407  \n",
              "2017-01-13        1.0  -0.607407 -0.522222  \n",
              "2017-01-14        1.0  -0.522222 -0.644444  \n",
              "2017-01-16        1.0  -0.644444 -0.344444  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8724eab-fdf0-407f-bf11-99ae2709a7f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-7)</th>\n",
              "      <th>var2(t-7)</th>\n",
              "      <th>var3(t-7)</th>\n",
              "      <th>var1(t-6)</th>\n",
              "      <th>var2(t-6)</th>\n",
              "      <th>var3(t-6)</th>\n",
              "      <th>var1(t-5)</th>\n",
              "      <th>var2(t-5)</th>\n",
              "      <th>var3(t-5)</th>\n",
              "      <th>var1(t-4)</th>\n",
              "      <th>...</th>\n",
              "      <th>var1(t-3)</th>\n",
              "      <th>var2(t-3)</th>\n",
              "      <th>var3(t-3)</th>\n",
              "      <th>var1(t-2)</th>\n",
              "      <th>var2(t-2)</th>\n",
              "      <th>var3(t-2)</th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var2(t-1)</th>\n",
              "      <th>var3(t-1)</th>\n",
              "      <th>var3(t)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fecha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.314815</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-13</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-14</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>-0.644444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-16</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.644444</td>\n",
              "      <td>-0.344444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8724eab-fdf0-407f-bf11-99ae2709a7f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8724eab-fdf0-407f-bf11-99ae2709a7f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8724eab-fdf0-407f-bf11-99ae2709a7f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIVIDIR EN TRAIN Y TEST\n",
        "\n",
        "values = newReframed.values\n",
        "n_train_days = 315+289 - (30+PASOS)\n",
        "train = values[:n_train_days, :]\n",
        "test = values[n_train_days:, :]\n",
        "# split into input and outputs\n",
        "x_train, y_train = train[:, :-1], train[:, -1]\n",
        "x_val, y_val = test[:, :-1], test[:, -1]\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
        "x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
        "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Kh0GlU4o12",
        "outputId": "1c73227d-6242-4e09-ad0f-92050afb2f6c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(567, 1, 21) (567,) (30, 1, 21) (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARQUITECTURA DE LA RED NEURONAL\n",
        "  # mantener nueva capa oculta\n",
        "  # usar optimizador Nadam\n",
        "\n",
        "def crear_modeloFF():\n",
        "    model = Sequential() \n",
        "    model.add(Dense(PASOS, input_shape=(1,PASOS*3),activation='tanh')) # se multiplica el número de pasos anteriores (7) por 3 (total de variables que se usa ahora)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4, input_shape=(1,PASOS*3),activation='tanh')) \n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(loss='mean_absolute_error',optimizer='Nadam',metrics=[\"mse\"])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "iidDHEko41ir"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=60\n",
        "\n",
        "model = crear_modeloFF()\n",
        "\n",
        "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asxoxy2B41oR",
        "outputId": "16232aaf-7492-45ee-ff2f-9c3087bdc074"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 1, 7)              154       \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 191\n",
            "Trainable params: 191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "81/81 [==============================] - 1s 4ms/step - loss: 0.2690 - mse: 0.1257 - val_loss: 0.1620 - val_mse: 0.0478\n",
            "Epoch 2/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.2307 - mse: 0.0913 - val_loss: 0.1780 - val_mse: 0.0515\n",
            "Epoch 3/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.2100 - mse: 0.0762 - val_loss: 0.1826 - val_mse: 0.0563\n",
            "Epoch 4/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1991 - mse: 0.0699 - val_loss: 0.1653 - val_mse: 0.0490\n",
            "Epoch 5/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1945 - mse: 0.0671 - val_loss: 0.1734 - val_mse: 0.0543\n",
            "Epoch 6/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1909 - mse: 0.0660 - val_loss: 0.1724 - val_mse: 0.0542\n",
            "Epoch 7/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1882 - mse: 0.0652 - val_loss: 0.1974 - val_mse: 0.0675\n",
            "Epoch 8/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1854 - mse: 0.0649 - val_loss: 0.1686 - val_mse: 0.0530\n",
            "Epoch 9/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1831 - mse: 0.0641 - val_loss: 0.1769 - val_mse: 0.0569\n",
            "Epoch 10/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1782 - mse: 0.0624 - val_loss: 0.1610 - val_mse: 0.0510\n",
            "Epoch 11/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1744 - mse: 0.0603 - val_loss: 0.1672 - val_mse: 0.0565\n",
            "Epoch 12/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1720 - mse: 0.0589 - val_loss: 0.1719 - val_mse: 0.0591\n",
            "Epoch 13/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1711 - mse: 0.0589 - val_loss: 0.1613 - val_mse: 0.0521\n",
            "Epoch 14/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1695 - mse: 0.0590 - val_loss: 0.1580 - val_mse: 0.0512\n",
            "Epoch 15/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1676 - mse: 0.0591 - val_loss: 0.1642 - val_mse: 0.0562\n",
            "Epoch 16/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1674 - mse: 0.0582 - val_loss: 0.1622 - val_mse: 0.0552\n",
            "Epoch 17/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1661 - mse: 0.0587 - val_loss: 0.1542 - val_mse: 0.0512\n",
            "Epoch 18/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1665 - mse: 0.0580 - val_loss: 0.1505 - val_mse: 0.0493\n",
            "Epoch 19/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1646 - mse: 0.0577 - val_loss: 0.1528 - val_mse: 0.0502\n",
            "Epoch 20/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1641 - mse: 0.0583 - val_loss: 0.1563 - val_mse: 0.0520\n",
            "Epoch 21/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1625 - mse: 0.0565 - val_loss: 0.1517 - val_mse: 0.0491\n",
            "Epoch 22/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1627 - mse: 0.0559 - val_loss: 0.1593 - val_mse: 0.0531\n",
            "Epoch 23/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1625 - mse: 0.0571 - val_loss: 0.1547 - val_mse: 0.0500\n",
            "Epoch 24/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1615 - mse: 0.0555 - val_loss: 0.1522 - val_mse: 0.0487\n",
            "Epoch 25/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1601 - mse: 0.0548 - val_loss: 0.1468 - val_mse: 0.0467\n",
            "Epoch 26/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1605 - mse: 0.0558 - val_loss: 0.1515 - val_mse: 0.0485\n",
            "Epoch 27/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1605 - mse: 0.0551 - val_loss: 0.1442 - val_mse: 0.0464\n",
            "Epoch 28/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1598 - mse: 0.0552 - val_loss: 0.1582 - val_mse: 0.0497\n",
            "Epoch 29/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1584 - mse: 0.0551 - val_loss: 0.1683 - val_mse: 0.0562\n",
            "Epoch 30/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1577 - mse: 0.0550 - val_loss: 0.1646 - val_mse: 0.0545\n",
            "Epoch 31/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1573 - mse: 0.0539 - val_loss: 0.1520 - val_mse: 0.0488\n",
            "Epoch 32/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1577 - mse: 0.0549 - val_loss: 0.1521 - val_mse: 0.0502\n",
            "Epoch 33/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1568 - mse: 0.0545 - val_loss: 0.1515 - val_mse: 0.0482\n",
            "Epoch 34/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1564 - mse: 0.0536 - val_loss: 0.1495 - val_mse: 0.0433\n",
            "Epoch 35/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1566 - mse: 0.0539 - val_loss: 0.1582 - val_mse: 0.0531\n",
            "Epoch 36/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1559 - mse: 0.0534 - val_loss: 0.1444 - val_mse: 0.0430\n",
            "Epoch 37/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1543 - mse: 0.0532 - val_loss: 0.1508 - val_mse: 0.0488\n",
            "Epoch 38/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1539 - mse: 0.0528 - val_loss: 0.1624 - val_mse: 0.0541\n",
            "Epoch 39/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1539 - mse: 0.0528 - val_loss: 0.1592 - val_mse: 0.0507\n",
            "Epoch 40/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1531 - mse: 0.0524 - val_loss: 0.1569 - val_mse: 0.0520\n",
            "Epoch 41/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1521 - mse: 0.0514 - val_loss: 0.1617 - val_mse: 0.0526\n",
            "Epoch 42/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1529 - mse: 0.0527 - val_loss: 0.1533 - val_mse: 0.0485\n",
            "Epoch 43/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1527 - mse: 0.0527 - val_loss: 0.1421 - val_mse: 0.0391\n",
            "Epoch 44/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1522 - mse: 0.0520 - val_loss: 0.1476 - val_mse: 0.0430\n",
            "Epoch 45/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1525 - mse: 0.0506 - val_loss: 0.1507 - val_mse: 0.0435\n",
            "Epoch 46/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1519 - mse: 0.0513 - val_loss: 0.1452 - val_mse: 0.0407\n",
            "Epoch 47/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1512 - mse: 0.0510 - val_loss: 0.1457 - val_mse: 0.0420\n",
            "Epoch 48/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1512 - mse: 0.0513 - val_loss: 0.1526 - val_mse: 0.0447\n",
            "Epoch 49/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1489 - mse: 0.0512 - val_loss: 0.1480 - val_mse: 0.0432\n",
            "Epoch 50/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1500 - mse: 0.0507 - val_loss: 0.1406 - val_mse: 0.0385\n",
            "Epoch 51/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1497 - mse: 0.0508 - val_loss: 0.1422 - val_mse: 0.0406\n",
            "Epoch 52/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1500 - mse: 0.0513 - val_loss: 0.1492 - val_mse: 0.0433\n",
            "Epoch 53/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1499 - mse: 0.0497 - val_loss: 0.1403 - val_mse: 0.0391\n",
            "Epoch 54/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1491 - mse: 0.0506 - val_loss: 0.1419 - val_mse: 0.0378\n",
            "Epoch 55/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1489 - mse: 0.0493 - val_loss: 0.1456 - val_mse: 0.0404\n",
            "Epoch 56/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1488 - mse: 0.0500 - val_loss: 0.1388 - val_mse: 0.0371\n",
            "Epoch 57/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1470 - mse: 0.0494 - val_loss: 0.1430 - val_mse: 0.0387\n",
            "Epoch 58/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1468 - mse: 0.0486 - val_loss: 0.1715 - val_mse: 0.0536\n",
            "Epoch 59/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1491 - mse: 0.0506 - val_loss: 0.1558 - val_mse: 0.0452\n",
            "Epoch 60/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1480 - mse: 0.0499 - val_loss: 0.1406 - val_mse: 0.0371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARQUITECTURA DE LA RED NEURONAL\n",
        "  # aumentar neuronas de la capa oculta (de 4 a 6)\n",
        "  # usar optimizador RMSprop\n",
        "\n",
        "def crear_modeloFF():\n",
        "    model1 = Sequential() \n",
        "    model1.add(Dense(PASOS, input_shape=(1,PASOS*3),activation='tanh')) # se multiplica el número de pasos anteriores (7) por 3 (total de variables que se usa ahora)\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dense(6, input_shape=(1,PASOS*3),activation='tanh'))\n",
        "    model1.add(Dense(1, activation='tanh'))\n",
        "    model1.compile(loss='mean_absolute_error', optimizer='RMSprop', metrics=[\"mse\"])\n",
        "    model1.summary()\n",
        "    return model1"
      ],
      "metadata": {
        "id": "xErnjDK8BQhm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50\n",
        "\n",
        "model1 = crear_modeloFF()\n",
        "\n",
        "history=model1.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf_fywyxBYl6",
        "outputId": "4d3da4e7-1ceb-425c-d641-7799b423c901"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 1, 7)              154       \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 6)                 48        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209\n",
            "Trainable params: 209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "81/81 [==============================] - 3s 14ms/step - loss: 0.5078 - mse: 0.4202 - val_loss: 0.1817 - val_mse: 0.0537\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2471 - mse: 0.1047 - val_loss: 0.2320 - val_mse: 0.0818\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.2146 - mse: 0.0784 - val_loss: 0.1767 - val_mse: 0.0514\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2011 - mse: 0.0710 - val_loss: 0.1849 - val_mse: 0.0563\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1933 - mse: 0.0668 - val_loss: 0.1566 - val_mse: 0.0422\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1876 - mse: 0.0647 - val_loss: 0.1566 - val_mse: 0.0425\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1829 - mse: 0.0622 - val_loss: 0.1640 - val_mse: 0.0480\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1802 - mse: 0.0607 - val_loss: 0.1736 - val_mse: 0.0534\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1780 - mse: 0.0608 - val_loss: 0.1690 - val_mse: 0.0506\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1751 - mse: 0.0592 - val_loss: 0.1507 - val_mse: 0.0401\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1751 - mse: 0.0588 - val_loss: 0.1538 - val_mse: 0.0418\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1719 - mse: 0.0580 - val_loss: 0.1749 - val_mse: 0.0531\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1692 - mse: 0.0568 - val_loss: 0.1781 - val_mse: 0.0537\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1712 - mse: 0.0575 - val_loss: 0.1378 - val_mse: 0.0363\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1697 - mse: 0.0564 - val_loss: 0.1601 - val_mse: 0.0455\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1698 - mse: 0.0563 - val_loss: 0.1649 - val_mse: 0.0483\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1682 - mse: 0.0562 - val_loss: 0.1812 - val_mse: 0.0553\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1667 - mse: 0.0555 - val_loss: 0.1633 - val_mse: 0.0474\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1639 - mse: 0.0544 - val_loss: 0.1456 - val_mse: 0.0399\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1665 - mse: 0.0562 - val_loss: 0.1522 - val_mse: 0.0423\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1632 - mse: 0.0543 - val_loss: 0.1434 - val_mse: 0.0390\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1641 - mse: 0.0551 - val_loss: 0.1568 - val_mse: 0.0450\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1631 - mse: 0.0549 - val_loss: 0.1425 - val_mse: 0.0387\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1627 - mse: 0.0529 - val_loss: 0.1940 - val_mse: 0.0608\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1634 - mse: 0.0534 - val_loss: 0.1702 - val_mse: 0.0495\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1630 - mse: 0.0542 - val_loss: 0.1518 - val_mse: 0.0429\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1611 - mse: 0.0540 - val_loss: 0.1489 - val_mse: 0.0441\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1630 - mse: 0.0547 - val_loss: 0.1636 - val_mse: 0.0474\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1614 - mse: 0.0542 - val_loss: 0.1810 - val_mse: 0.0552\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1604 - mse: 0.0544 - val_loss: 0.1444 - val_mse: 0.0411\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1599 - mse: 0.0539 - val_loss: 0.1585 - val_mse: 0.0454\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1596 - mse: 0.0532 - val_loss: 0.1365 - val_mse: 0.0383\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1596 - mse: 0.0534 - val_loss: 0.1674 - val_mse: 0.0491\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1587 - mse: 0.0535 - val_loss: 0.1617 - val_mse: 0.0473\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1576 - mse: 0.0516 - val_loss: 0.1678 - val_mse: 0.0495\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1589 - mse: 0.0526 - val_loss: 0.1661 - val_mse: 0.0483\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1577 - mse: 0.0532 - val_loss: 0.1764 - val_mse: 0.0521\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1573 - mse: 0.0531 - val_loss: 0.1534 - val_mse: 0.0427\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1571 - mse: 0.0526 - val_loss: 0.1409 - val_mse: 0.0391\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1570 - mse: 0.0522 - val_loss: 0.1425 - val_mse: 0.0393\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1568 - mse: 0.0531 - val_loss: 0.1450 - val_mse: 0.0410\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1560 - mse: 0.0522 - val_loss: 0.1533 - val_mse: 0.0432\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1555 - mse: 0.0528 - val_loss: 0.1652 - val_mse: 0.0501\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1570 - mse: 0.0521 - val_loss: 0.1383 - val_mse: 0.0382\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1567 - mse: 0.0526 - val_loss: 0.1364 - val_mse: 0.0372\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1543 - mse: 0.0518 - val_loss: 0.1666 - val_mse: 0.0494\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1555 - mse: 0.0515 - val_loss: 0.1385 - val_mse: 0.0387\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1557 - mse: 0.0518 - val_loss: 0.1354 - val_mse: 0.0380\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1557 - mse: 0.0529 - val_loss: 0.1364 - val_mse: 0.0375\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1549 - mse: 0.0520 - val_loss: 0.1749 - val_mse: 0.0524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARQUITECTURA DE LA RED NEURONAL\n",
        "  # usar optmizador Adam\n",
        "  # mantener nuevo número de neuronas (6)\n",
        "\n",
        "def crear_modeloFF():\n",
        "    model2 = Sequential() \n",
        "    model2.add(Dense(PASOS, input_shape=(1,PASOS*3),activation='tanh')) # se multiplica el número de pasos anteriores (7) por 3 (total de variables que se usa ahora)\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(6, input_shape=(1,PASOS*3),activation='tanh'))\n",
        "    model2.add(Dense(1, activation='tanh'))\n",
        "    model2.compile(loss='mean_absolute_error', optimizer='Adam', metrics=[\"mse\"])\n",
        "    model2.summary()\n",
        "    return model2"
      ],
      "metadata": {
        "id": "J0UO7Olw5pQk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=60\n",
        "\n",
        "model2 = crear_modeloFF()\n",
        "\n",
        "history=model2.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbtK-Aw75vXu",
        "outputId": "3b4aa981-b498-4456-a106-32a3cd1c78e3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 1, 7)              154       \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 6)                 48        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209\n",
            "Trainable params: 209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "81/81 [==============================] - 2s 8ms/step - loss: 0.3146 - mse: 0.1740 - val_loss: 0.2014 - val_mse: 0.0711\n",
            "Epoch 2/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2137 - mse: 0.0794 - val_loss: 0.1790 - val_mse: 0.0551\n",
            "Epoch 3/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1968 - mse: 0.0710 - val_loss: 0.1554 - val_mse: 0.0446\n",
            "Epoch 4/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1896 - mse: 0.0684 - val_loss: 0.1567 - val_mse: 0.0445\n",
            "Epoch 5/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1858 - mse: 0.0668 - val_loss: 0.1953 - val_mse: 0.0598\n",
            "Epoch 6/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1838 - mse: 0.0646 - val_loss: 0.1709 - val_mse: 0.0493\n",
            "Epoch 7/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1815 - mse: 0.0629 - val_loss: 0.1975 - val_mse: 0.0610\n",
            "Epoch 8/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1788 - mse: 0.0633 - val_loss: 0.1680 - val_mse: 0.0478\n",
            "Epoch 9/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1791 - mse: 0.0631 - val_loss: 0.1798 - val_mse: 0.0527\n",
            "Epoch 10/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1759 - mse: 0.0625 - val_loss: 0.1869 - val_mse: 0.0560\n",
            "Epoch 11/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1756 - mse: 0.0616 - val_loss: 0.1624 - val_mse: 0.0460\n",
            "Epoch 12/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1741 - mse: 0.0616 - val_loss: 0.2028 - val_mse: 0.0641\n",
            "Epoch 13/60\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.1725 - mse: 0.0596 - val_loss: 0.1639 - val_mse: 0.0470\n",
            "Epoch 14/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1744 - mse: 0.0610 - val_loss: 0.1875 - val_mse: 0.0571\n",
            "Epoch 15/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1712 - mse: 0.0597 - val_loss: 0.1981 - val_mse: 0.0623\n",
            "Epoch 16/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1703 - mse: 0.0600 - val_loss: 0.1892 - val_mse: 0.0578\n",
            "Epoch 17/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1699 - mse: 0.0601 - val_loss: 0.1916 - val_mse: 0.0604\n",
            "Epoch 18/60\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1698 - mse: 0.0593 - val_loss: 0.1635 - val_mse: 0.0475\n",
            "Epoch 19/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1691 - mse: 0.0590 - val_loss: 0.1792 - val_mse: 0.0541\n",
            "Epoch 20/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1672 - mse: 0.0587 - val_loss: 0.1996 - val_mse: 0.0643\n",
            "Epoch 21/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1671 - mse: 0.0583 - val_loss: 0.1796 - val_mse: 0.0548\n",
            "Epoch 22/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1666 - mse: 0.0582 - val_loss: 0.1709 - val_mse: 0.0508\n",
            "Epoch 23/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1675 - mse: 0.0592 - val_loss: 0.1694 - val_mse: 0.0508\n",
            "Epoch 24/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1647 - mse: 0.0560 - val_loss: 0.2022 - val_mse: 0.0674\n",
            "Epoch 25/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1626 - mse: 0.0562 - val_loss: 0.1380 - val_mse: 0.0391\n",
            "Epoch 26/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1626 - mse: 0.0558 - val_loss: 0.1571 - val_mse: 0.0459\n",
            "Epoch 27/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1635 - mse: 0.0573 - val_loss: 0.1821 - val_mse: 0.0557\n",
            "Epoch 28/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1633 - mse: 0.0563 - val_loss: 0.2208 - val_mse: 0.0769\n",
            "Epoch 29/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1635 - mse: 0.0565 - val_loss: 0.1681 - val_mse: 0.0498\n",
            "Epoch 30/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1610 - mse: 0.0565 - val_loss: 0.1750 - val_mse: 0.0533\n",
            "Epoch 31/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1594 - mse: 0.0557 - val_loss: 0.1598 - val_mse: 0.0472\n",
            "Epoch 32/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1603 - mse: 0.0556 - val_loss: 0.1701 - val_mse: 0.0507\n",
            "Epoch 33/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1586 - mse: 0.0541 - val_loss: 0.1402 - val_mse: 0.0399\n",
            "Epoch 34/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1620 - mse: 0.0548 - val_loss: 0.1959 - val_mse: 0.0625\n",
            "Epoch 35/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1598 - mse: 0.0561 - val_loss: 0.1488 - val_mse: 0.0423\n",
            "Epoch 36/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1585 - mse: 0.0545 - val_loss: 0.1545 - val_mse: 0.0448\n",
            "Epoch 37/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1610 - mse: 0.0557 - val_loss: 0.1670 - val_mse: 0.0505\n",
            "Epoch 38/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1587 - mse: 0.0547 - val_loss: 0.1378 - val_mse: 0.0403\n",
            "Epoch 39/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1594 - mse: 0.0549 - val_loss: 0.1346 - val_mse: 0.0383\n",
            "Epoch 40/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1576 - mse: 0.0542 - val_loss: 0.1380 - val_mse: 0.0388\n",
            "Epoch 41/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1571 - mse: 0.0523 - val_loss: 0.1358 - val_mse: 0.0394\n",
            "Epoch 42/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1568 - mse: 0.0536 - val_loss: 0.1319 - val_mse: 0.0377\n",
            "Epoch 43/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1568 - mse: 0.0533 - val_loss: 0.1625 - val_mse: 0.0473\n",
            "Epoch 44/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1570 - mse: 0.0533 - val_loss: 0.1665 - val_mse: 0.0489\n",
            "Epoch 45/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1563 - mse: 0.0525 - val_loss: 0.1566 - val_mse: 0.0458\n",
            "Epoch 46/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1559 - mse: 0.0536 - val_loss: 0.1591 - val_mse: 0.0461\n",
            "Epoch 47/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1538 - mse: 0.0524 - val_loss: 0.1510 - val_mse: 0.0458\n",
            "Epoch 48/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1559 - mse: 0.0531 - val_loss: 0.1408 - val_mse: 0.0418\n",
            "Epoch 49/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1544 - mse: 0.0525 - val_loss: 0.1374 - val_mse: 0.0392\n",
            "Epoch 50/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1558 - mse: 0.0524 - val_loss: 0.1362 - val_mse: 0.0392\n",
            "Epoch 51/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1551 - mse: 0.0524 - val_loss: 0.1560 - val_mse: 0.0460\n",
            "Epoch 52/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1545 - mse: 0.0520 - val_loss: 0.1449 - val_mse: 0.0417\n",
            "Epoch 53/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1555 - mse: 0.0526 - val_loss: 0.1438 - val_mse: 0.0402\n",
            "Epoch 54/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1538 - mse: 0.0518 - val_loss: 0.1469 - val_mse: 0.0430\n",
            "Epoch 55/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1558 - mse: 0.0531 - val_loss: 0.1506 - val_mse: 0.0445\n",
            "Epoch 56/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1544 - mse: 0.0523 - val_loss: 0.1567 - val_mse: 0.0459\n",
            "Epoch 57/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1542 - mse: 0.0519 - val_loss: 0.1458 - val_mse: 0.0416\n",
            "Epoch 58/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1534 - mse: 0.0524 - val_loss: 0.1319 - val_mse: 0.0365\n",
            "Epoch 59/60\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1523 - mse: 0.0515 - val_loss: 0.1508 - val_mse: 0.0446\n",
            "Epoch 60/60\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1524 - mse: 0.0508 - val_loss: 0.1245 - val_mse: 0.0342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de esta red son menores a la anterior, incluso inferiores a la del ejercicio original (0.1514). El modelo de serie temporal de 1 variable y este (múltiples variables) comienzan a distar cuando se aplica cambios en el número de neuronas (paso de 4 a 6 y mantengo optimizador)."
      ],
      "metadata": {
        "id": "DrNGYVvoAzXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "plt.title('loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.title('validate loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "RFtW1c-IEidc",
        "outputId": "75d9960d-304d-48bb-a088-96b3656bc733"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en la Parte 1 la curva de validación sigue siendo algo errática, pero se ha conseguido bajar los valores de loss, de 0.1514 a 0.1480 y mse de 0.0527 a 0.0499.\n",
        "\n",
        "# TERCERA PARTE \n",
        "\n",
        "## RED NEURONAL CON **EMBEDDINGS**"
      ],
      "metadata": {
        "id": "hWD8Gy47E12L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NUEVAS LIBRERÍAS\n",
        "\n",
        "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate, LSTM\n",
        "from keras.layers import BatchNormalization, SpatialDropout1D\n",
        "from keras.callbacks import Callback\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbagnato/machine-learning/master/time_series.csv\"\n",
        "df = pd.read_csv(url, parse_dates=[0], header=None, index_col=0, names=['fecha','unidades'])\n",
        "\n",
        "df['weekday']=[x.weekday() for x in df.index]\n",
        "df['month']=[x.month for x in df.index]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "7r4SC5rjJ5E9",
        "outputId": "bd71d4a8-3343-48cf-d21f-b0db319fe38f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            unidades  weekday  month\n",
              "fecha                               \n",
              "2017-01-02       236        0      1\n",
              "2017-01-03       237        1      1\n",
              "2017-01-04       290        2      1\n",
              "2017-01-05       221        3      1\n",
              "2017-01-07       128        5      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-718ab0ca-bbcf-4bd8-8b7e-9c847349e22d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unidades</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fecha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-02</th>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03</th>\n",
              "      <td>237</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04</th>\n",
              "      <td>290</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-05</th>\n",
              "      <td>221</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-07</th>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-718ab0ca-bbcf-4bd8-8b7e-9c847349e22d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-718ab0ca-bbcf-4bd8-8b7e-9c847349e22d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-718ab0ca-bbcf-4bd8-8b7e-9c847349e22d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROCESADO DE LOS DATOS\n",
        "\n",
        "PASOS=7\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "metadata": {
        "id": "TUvl3UCVKbej"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "values = df['unidades'].values\n",
        "\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
        "\n",
        "scaled = scaler.fit_transform(values)\n",
        "\n",
        "reframed = series_to_supervised(scaled, PASOS, 1)\n",
        "reframed.reset_index(inplace=True, drop=True)\n",
        "\n",
        "contador=0\n",
        "reframed['weekday']=df['weekday']\n",
        "reframed['month']=df['month']\n",
        "\n",
        "for i in range(reframed.index[0],reframed.index[-1]):\n",
        "    reframed['weekday'].loc[contador]=df['weekday'][i+8]\n",
        "    reframed['month'].loc[contador]=df['month'][i+8]\n",
        "    contador=contador+1\n",
        "reframed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "5C_5564ZKez4",
        "outputId": "965b1014-7b1c-4b02-a36f-dbba72890c8d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   var1(t-7)  var1(t-6)  var1(t-5)  var1(t-4)  var1(t-3)  var1(t-2)  \\\n",
              "0  -0.314815  -0.311111  -0.114815  -0.370370  -0.714815  -0.103704   \n",
              "1  -0.311111  -0.114815  -0.370370  -0.714815  -0.103704  -0.225926   \n",
              "2  -0.114815  -0.370370  -0.714815  -0.103704  -0.225926  -0.433333   \n",
              "3  -0.370370  -0.714815  -0.103704  -0.225926  -0.433333  -0.607407   \n",
              "4  -0.714815  -0.103704  -0.225926  -0.433333  -0.607407  -0.522222   \n",
              "\n",
              "   var1(t-1)   var1(t)  weekday  month  \n",
              "0  -0.225926 -0.433333      3.0    1.0  \n",
              "1  -0.433333 -0.607407      4.0    1.0  \n",
              "2  -0.607407 -0.522222      5.0    1.0  \n",
              "3  -0.522222 -0.644444      0.0    1.0  \n",
              "4  -0.644444 -0.344444      1.0    1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15f7503a-050e-465f-94a5-4eca49fc7ae7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-7)</th>\n",
              "      <th>var1(t-6)</th>\n",
              "      <th>var1(t-5)</th>\n",
              "      <th>var1(t-4)</th>\n",
              "      <th>var1(t-3)</th>\n",
              "      <th>var1(t-2)</th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.314815</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.311111</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>-0.644444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>-0.644444</td>\n",
              "      <td>-0.344444</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15f7503a-050e-465f-94a5-4eca49fc7ae7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15f7503a-050e-465f-94a5-4eca49fc7ae7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15f7503a-050e-465f-94a5-4eca49fc7ae7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reordenado=reframed[ ['weekday','month','var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)','var1(t)'] ]\n",
        "reordenado.dropna(inplace=True)\n",
        "reordenado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "8PWBgYexKqaH",
        "outputId": "b6c63993-63ae-4e0b-f17c-b67896ece9c8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     weekday  month  var1(t-7)  var1(t-6)  var1(t-5)  var1(t-4)  var1(t-3)  \\\n",
              "0        3.0    1.0  -0.314815  -0.311111  -0.114815  -0.370370  -0.714815   \n",
              "1        4.0    1.0  -0.311111  -0.114815  -0.370370  -0.714815  -0.103704   \n",
              "2        5.0    1.0  -0.114815  -0.370370  -0.714815  -0.103704  -0.225926   \n",
              "3        0.0    1.0  -0.370370  -0.714815  -0.103704  -0.225926  -0.433333   \n",
              "4        1.0    1.0  -0.714815  -0.103704  -0.225926  -0.433333  -0.607407   \n",
              "..       ...    ...        ...        ...        ...        ...        ...   \n",
              "591      0.0   11.0  -0.777778  -0.422222  -0.425926  -0.511111  -0.448148   \n",
              "592      1.0   11.0  -0.422222  -0.425926  -0.511111  -0.448148  -0.496296   \n",
              "593      2.0   11.0  -0.425926  -0.511111  -0.448148  -0.496296  -0.488889   \n",
              "594      3.0   11.0  -0.511111  -0.448148  -0.496296  -0.488889  -0.907407   \n",
              "595      4.0   11.0  -0.448148  -0.496296  -0.488889  -0.907407  -0.166667   \n",
              "\n",
              "     var1(t-2)  var1(t-1)   var1(t)  \n",
              "0    -0.103704  -0.225926 -0.433333  \n",
              "1    -0.225926  -0.433333 -0.607407  \n",
              "2    -0.433333  -0.607407 -0.522222  \n",
              "3    -0.607407  -0.522222 -0.644444  \n",
              "4    -0.522222  -0.644444 -0.344444  \n",
              "..         ...        ...       ...  \n",
              "591  -0.496296  -0.488889 -0.907407  \n",
              "592  -0.488889  -0.907407 -0.166667  \n",
              "593  -0.907407  -0.166667 -0.374074  \n",
              "594  -0.166667  -0.374074 -0.511111  \n",
              "595  -0.374074  -0.511111 -0.259259  \n",
              "\n",
              "[596 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2680711-cd94-4f05-a0a6-b621e6e25397\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>var1(t-7)</th>\n",
              "      <th>var1(t-6)</th>\n",
              "      <th>var1(t-5)</th>\n",
              "      <th>var1(t-4)</th>\n",
              "      <th>var1(t-3)</th>\n",
              "      <th>var1(t-2)</th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.314815</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.311111</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.114815</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>-0.644444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.714815</td>\n",
              "      <td>-0.103704</td>\n",
              "      <td>-0.225926</td>\n",
              "      <td>-0.433333</td>\n",
              "      <td>-0.607407</td>\n",
              "      <td>-0.522222</td>\n",
              "      <td>-0.644444</td>\n",
              "      <td>-0.344444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-0.777778</td>\n",
              "      <td>-0.422222</td>\n",
              "      <td>-0.425926</td>\n",
              "      <td>-0.511111</td>\n",
              "      <td>-0.448148</td>\n",
              "      <td>-0.496296</td>\n",
              "      <td>-0.488889</td>\n",
              "      <td>-0.907407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-0.422222</td>\n",
              "      <td>-0.425926</td>\n",
              "      <td>-0.511111</td>\n",
              "      <td>-0.448148</td>\n",
              "      <td>-0.496296</td>\n",
              "      <td>-0.488889</td>\n",
              "      <td>-0.907407</td>\n",
              "      <td>-0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-0.425926</td>\n",
              "      <td>-0.511111</td>\n",
              "      <td>-0.448148</td>\n",
              "      <td>-0.496296</td>\n",
              "      <td>-0.488889</td>\n",
              "      <td>-0.907407</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-0.374074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-0.511111</td>\n",
              "      <td>-0.448148</td>\n",
              "      <td>-0.496296</td>\n",
              "      <td>-0.488889</td>\n",
              "      <td>-0.907407</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-0.374074</td>\n",
              "      <td>-0.511111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-0.448148</td>\n",
              "      <td>-0.496296</td>\n",
              "      <td>-0.488889</td>\n",
              "      <td>-0.907407</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-0.374074</td>\n",
              "      <td>-0.511111</td>\n",
              "      <td>-0.259259</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>596 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2680711-cd94-4f05-a0a6-b621e6e25397')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2680711-cd94-4f05-a0a6-b621e6e25397 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2680711-cd94-4f05-a0a6-b621e6e25397');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIVIDIR EN TRAIN Y TEST\n",
        "\n",
        "training_data = reordenado.drop('var1(t)',axis=1)#.values\n",
        "target_data=reordenado['var1(t)']\n",
        "#training_data.head()\n",
        "valid_data = training_data[595-30:595]\n",
        "valid_target=target_data[595-30:595]\n",
        "\n",
        "training_data = training_data[0:595]\n",
        "target_data=target_data[0:595]\n",
        "print(training_data.shape,target_data.shape,valid_data.shape,valid_target.shape)\n",
        "#training_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhfySLuaKsmy",
        "outputId": "4a050572-f049-4b16-b3c0-e7eb4ea62150"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(595, 9) (595,) (30, 9) (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARQUITECTURA DE RED NEURONAL\n",
        "  # añadir capa oculta con 4 neuronas\n",
        "\n",
        "\n",
        "def crear_modeloEmbeddings():\n",
        "    emb_dias = 2 #tamaño profundidad de embeddings\n",
        "    emb_meses = 4\n",
        "\n",
        "    in_dias = Input(shape=[1], name = 'dias')\n",
        "    emb_dias = Embedding(7+1, emb_dias)(in_dias)\n",
        "    in_meses = Input(shape=[1], name = 'meses')\n",
        "    emb_meses = Embedding(12+1, emb_meses)(in_meses)\n",
        "\n",
        "    in_cli = Input(shape=[PASOS], name = 'cli')\n",
        "\n",
        "    fe = concatenate([(emb_dias), (emb_meses)])\n",
        "\n",
        "    x = Flatten()(fe)\n",
        "    x = Dense(PASOS,activation='tanh')(x)\n",
        "    x = Dense(4,activation='tanh')(x)\n",
        "    outp = Dense(1,activation='tanh')(x)\n",
        "    model = Model(inputs=[in_dias,in_meses,in_cli], outputs=outp)\n",
        "\n",
        "    model.compile(loss='mean_absolute_error', \n",
        "                  optimizer='adam',\n",
        "                  metrics=['MSE'])\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "se7syPU9Kvg_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ENTRENAMIENTO \n",
        "\n",
        "EPOCHS=40\n",
        "\n",
        "model = crear_modeloEmbeddings()\n",
        "\n",
        "continuas=training_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
        "valid_continuas=valid_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
        "\n",
        "history=model.fit([training_data['weekday'],training_data['month'],continuas], target_data, epochs=EPOCHS\n",
        "                 ,validation_data=([valid_data['weekday'],valid_data['month'],valid_continuas],valid_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhSDffbHLKGY",
        "outputId": "40fa7372-904a-49f9-be21-3cb9a1499e6b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " dias (InputLayer)              [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " meses (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 2)         16          ['dias[0][0]']                   \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 4)         52          ['meses[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 1, 6)         0           ['embedding[0][0]',              \n",
            "                                                                  'embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)            (None, 6)            0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 7)            49          ['flatten_7[0][0]']              \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 4)            32          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " cli (InputLayer)               [(None, 7)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 1)            5           ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 154\n",
            "Trainable params: 154\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n",
            "19/19 [==============================] - 1s 13ms/step - loss: 0.3297 - MSE: 0.1571 - val_loss: 0.3095 - val_MSE: 0.1387\n",
            "Epoch 2/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2238 - MSE: 0.0832 - val_loss: 0.1834 - val_MSE: 0.0634\n",
            "Epoch 3/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1897 - MSE: 0.0623 - val_loss: 0.1558 - val_MSE: 0.0472\n",
            "Epoch 4/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1714 - MSE: 0.0515 - val_loss: 0.1472 - val_MSE: 0.0424\n",
            "Epoch 5/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1555 - MSE: 0.0428 - val_loss: 0.1367 - val_MSE: 0.0361\n",
            "Epoch 6/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1425 - MSE: 0.0356 - val_loss: 0.1228 - val_MSE: 0.0287\n",
            "Epoch 7/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1316 - MSE: 0.0303 - val_loss: 0.1203 - val_MSE: 0.0264\n",
            "Epoch 8/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1237 - MSE: 0.0270 - val_loss: 0.1103 - val_MSE: 0.0231\n",
            "Epoch 9/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1176 - MSE: 0.0249 - val_loss: 0.1079 - val_MSE: 0.0223\n",
            "Epoch 10/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1140 - MSE: 0.0240 - val_loss: 0.1024 - val_MSE: 0.0214\n",
            "Epoch 11/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1114 - MSE: 0.0231 - val_loss: 0.0983 - val_MSE: 0.0204\n",
            "Epoch 12/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1098 - MSE: 0.0225 - val_loss: 0.0961 - val_MSE: 0.0203\n",
            "Epoch 13/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1097 - MSE: 0.0227 - val_loss: 0.0982 - val_MSE: 0.0205\n",
            "Epoch 14/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1093 - MSE: 0.0224 - val_loss: 0.0959 - val_MSE: 0.0202\n",
            "Epoch 15/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1094 - MSE: 0.0226 - val_loss: 0.0954 - val_MSE: 0.0199\n",
            "Epoch 16/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1095 - MSE: 0.0225 - val_loss: 0.0949 - val_MSE: 0.0202\n",
            "Epoch 17/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1096 - MSE: 0.0227 - val_loss: 0.0978 - val_MSE: 0.0203\n",
            "Epoch 18/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1092 - MSE: 0.0225 - val_loss: 0.0955 - val_MSE: 0.0199\n",
            "Epoch 19/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1093 - MSE: 0.0226 - val_loss: 0.0965 - val_MSE: 0.0203\n",
            "Epoch 20/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1095 - MSE: 0.0225 - val_loss: 0.0945 - val_MSE: 0.0193\n",
            "Epoch 21/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1095 - MSE: 0.0227 - val_loss: 0.0989 - val_MSE: 0.0205\n",
            "Epoch 22/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1097 - MSE: 0.0226 - val_loss: 0.0941 - val_MSE: 0.0197\n",
            "Epoch 23/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1091 - MSE: 0.0225 - val_loss: 0.0967 - val_MSE: 0.0203\n",
            "Epoch 24/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1089 - MSE: 0.0226 - val_loss: 0.0965 - val_MSE: 0.0201\n",
            "Epoch 25/40\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1093 - MSE: 0.0225 - val_loss: 0.0954 - val_MSE: 0.0201\n",
            "Epoch 26/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1096 - MSE: 0.0227 - val_loss: 0.1001 - val_MSE: 0.0207\n",
            "Epoch 27/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1094 - MSE: 0.0227 - val_loss: 0.0945 - val_MSE: 0.0193\n",
            "Epoch 28/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1093 - MSE: 0.0227 - val_loss: 0.0988 - val_MSE: 0.0207\n",
            "Epoch 29/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1090 - MSE: 0.0224 - val_loss: 0.0930 - val_MSE: 0.0195\n",
            "Epoch 30/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1088 - MSE: 0.0224 - val_loss: 0.0942 - val_MSE: 0.0199\n",
            "Epoch 31/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1094 - MSE: 0.0227 - val_loss: 0.0947 - val_MSE: 0.0202\n",
            "Epoch 32/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1090 - MSE: 0.0226 - val_loss: 0.0956 - val_MSE: 0.0202\n",
            "Epoch 33/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1090 - MSE: 0.0226 - val_loss: 0.0935 - val_MSE: 0.0196\n",
            "Epoch 34/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1086 - MSE: 0.0224 - val_loss: 0.0946 - val_MSE: 0.0196\n",
            "Epoch 35/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1089 - MSE: 0.0226 - val_loss: 0.0945 - val_MSE: 0.0197\n",
            "Epoch 36/40\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1087 - MSE: 0.0225 - val_loss: 0.0948 - val_MSE: 0.0198\n",
            "Epoch 37/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1087 - MSE: 0.0225 - val_loss: 0.0929 - val_MSE: 0.0195\n",
            "Epoch 38/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1090 - MSE: 0.0226 - val_loss: 0.0997 - val_MSE: 0.0211\n",
            "Epoch 39/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1090 - MSE: 0.0225 - val_loss: 0.0939 - val_MSE: 0.0196\n",
            "Epoch 40/40\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1092 - MSE: 0.0226 - val_loss: 0.0967 - val_MSE: 0.0201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('loss')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('validate loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "UGcCoJb7LTDj",
        "outputId": "48db9e8f-a34d-46b4-a935-445c2aadde3f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ENTRENAMIENTO \n",
        "\n",
        "EPOCHS=60\n",
        "\n",
        "model = crear_modeloEmbeddings()\n",
        "\n",
        "continuas=training_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
        "valid_continuas=valid_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
        "\n",
        "history=model.fit([training_data['weekday'],training_data['month'],continuas], target_data, epochs=EPOCHS\n",
        "                 ,validation_data=([valid_data['weekday'],valid_data['month'],valid_continuas],valid_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el0o4aueLo0H",
        "outputId": "7a12ea42-d1bf-43ed-a913-8924a7cecee2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " dias (InputLayer)              [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " meses (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 1, 2)         16          ['dias[0][0]']                   \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 1, 4)         52          ['meses[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 1, 6)         0           ['embedding_2[0][0]',            \n",
            "                                                                  'embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)            (None, 6)            0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 7)            49          ['flatten_8[0][0]']              \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 4)            32          ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " cli (InputLayer)               [(None, 7)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 1)            5           ['dense_25[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 154\n",
            "Trainable params: 154\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "19/19 [==============================] - 1s 12ms/step - loss: 0.3633 - MSE: 0.1845 - val_loss: 0.3347 - val_MSE: 0.1578\n",
            "Epoch 2/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2538 - MSE: 0.1019 - val_loss: 0.2051 - val_MSE: 0.0737\n",
            "Epoch 3/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2003 - MSE: 0.0686 - val_loss: 0.1627 - val_MSE: 0.0492\n",
            "Epoch 4/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1865 - MSE: 0.0594 - val_loss: 0.1564 - val_MSE: 0.0464\n",
            "Epoch 5/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1719 - MSE: 0.0514 - val_loss: 0.1465 - val_MSE: 0.0416\n",
            "Epoch 6/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1553 - MSE: 0.0427 - val_loss: 0.1335 - val_MSE: 0.0346\n",
            "Epoch 7/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1413 - MSE: 0.0351 - val_loss: 0.1229 - val_MSE: 0.0287\n",
            "Epoch 8/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1292 - MSE: 0.0293 - val_loss: 0.1111 - val_MSE: 0.0240\n",
            "Epoch 9/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1201 - MSE: 0.0257 - val_loss: 0.1050 - val_MSE: 0.0223\n",
            "Epoch 10/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1137 - MSE: 0.0239 - val_loss: 0.1006 - val_MSE: 0.0211\n",
            "Epoch 11/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1104 - MSE: 0.0229 - val_loss: 0.0955 - val_MSE: 0.0203\n",
            "Epoch 12/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1093 - MSE: 0.0228 - val_loss: 0.0948 - val_MSE: 0.0198\n",
            "Epoch 13/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1085 - MSE: 0.0224 - val_loss: 0.0931 - val_MSE: 0.0194\n",
            "Epoch 14/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1082 - MSE: 0.0223 - val_loss: 0.0932 - val_MSE: 0.0196\n",
            "Epoch 15/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0225 - val_loss: 0.0961 - val_MSE: 0.0201\n",
            "Epoch 16/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0224 - val_loss: 0.0975 - val_MSE: 0.0203\n",
            "Epoch 17/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - MSE: 0.0224 - val_loss: 0.0945 - val_MSE: 0.0200\n",
            "Epoch 18/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1083 - MSE: 0.0224 - val_loss: 0.0949 - val_MSE: 0.0201\n",
            "Epoch 19/60\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1079 - MSE: 0.0224 - val_loss: 0.0953 - val_MSE: 0.0200\n",
            "Epoch 20/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1080 - MSE: 0.0224 - val_loss: 0.0954 - val_MSE: 0.0199\n",
            "Epoch 21/60\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1083 - MSE: 0.0225 - val_loss: 0.0958 - val_MSE: 0.0199\n",
            "Epoch 22/60\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1080 - MSE: 0.0225 - val_loss: 0.0949 - val_MSE: 0.0198\n",
            "Epoch 23/60\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1083 - MSE: 0.0225 - val_loss: 0.0973 - val_MSE: 0.0203\n",
            "Epoch 24/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1077 - MSE: 0.0224 - val_loss: 0.0925 - val_MSE: 0.0194\n",
            "Epoch 25/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1080 - MSE: 0.0224 - val_loss: 0.0939 - val_MSE: 0.0195\n",
            "Epoch 26/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1079 - MSE: 0.0223 - val_loss: 0.0937 - val_MSE: 0.0197\n",
            "Epoch 27/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1081 - MSE: 0.0225 - val_loss: 0.0962 - val_MSE: 0.0202\n",
            "Epoch 28/60\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1083 - MSE: 0.0224 - val_loss: 0.0931 - val_MSE: 0.0195\n",
            "Epoch 29/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0227 - val_loss: 0.0972 - val_MSE: 0.0201\n",
            "Epoch 30/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1092 - MSE: 0.0226 - val_loss: 0.0930 - val_MSE: 0.0195\n",
            "Epoch 31/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0227 - val_loss: 0.0957 - val_MSE: 0.0200\n",
            "Epoch 32/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1080 - MSE: 0.0223 - val_loss: 0.0956 - val_MSE: 0.0201\n",
            "Epoch 33/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0226 - val_loss: 0.0935 - val_MSE: 0.0194\n",
            "Epoch 34/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0225 - val_loss: 0.0944 - val_MSE: 0.0197\n",
            "Epoch 35/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1091 - MSE: 0.0228 - val_loss: 0.0974 - val_MSE: 0.0201\n",
            "Epoch 36/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1080 - MSE: 0.0223 - val_loss: 0.0925 - val_MSE: 0.0194\n",
            "Epoch 37/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0961 - val_MSE: 0.0200\n",
            "Epoch 38/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1078 - MSE: 0.0225 - val_loss: 0.0944 - val_MSE: 0.0197\n",
            "Epoch 39/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1077 - MSE: 0.0224 - val_loss: 0.0946 - val_MSE: 0.0196\n",
            "Epoch 40/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1078 - MSE: 0.0223 - val_loss: 0.0939 - val_MSE: 0.0197\n",
            "Epoch 41/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1081 - MSE: 0.0227 - val_loss: 0.0949 - val_MSE: 0.0198\n",
            "Epoch 42/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0225 - val_loss: 0.0938 - val_MSE: 0.0194\n",
            "Epoch 43/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1075 - MSE: 0.0224 - val_loss: 0.0942 - val_MSE: 0.0198\n",
            "Epoch 44/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1077 - MSE: 0.0225 - val_loss: 0.0980 - val_MSE: 0.0205\n",
            "Epoch 45/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1076 - MSE: 0.0224 - val_loss: 0.0949 - val_MSE: 0.0199\n",
            "Epoch 46/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1076 - MSE: 0.0223 - val_loss: 0.0941 - val_MSE: 0.0200\n",
            "Epoch 47/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0225 - val_loss: 0.0948 - val_MSE: 0.0198\n",
            "Epoch 48/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1077 - MSE: 0.0225 - val_loss: 0.0964 - val_MSE: 0.0202\n",
            "Epoch 49/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1073 - MSE: 0.0223 - val_loss: 0.0936 - val_MSE: 0.0195\n",
            "Epoch 50/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1073 - MSE: 0.0224 - val_loss: 0.0966 - val_MSE: 0.0203\n",
            "Epoch 51/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1075 - MSE: 0.0223 - val_loss: 0.0938 - val_MSE: 0.0199\n",
            "Epoch 52/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1074 - MSE: 0.0224 - val_loss: 0.0956 - val_MSE: 0.0197\n",
            "Epoch 53/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1074 - MSE: 0.0224 - val_loss: 0.0957 - val_MSE: 0.0199\n",
            "Epoch 54/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1075 - MSE: 0.0223 - val_loss: 0.0971 - val_MSE: 0.0203\n",
            "Epoch 55/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1081 - MSE: 0.0226 - val_loss: 0.0916 - val_MSE: 0.0195\n",
            "Epoch 56/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1079 - MSE: 0.0226 - val_loss: 0.0959 - val_MSE: 0.0201\n",
            "Epoch 57/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1075 - MSE: 0.0224 - val_loss: 0.0933 - val_MSE: 0.0196\n",
            "Epoch 58/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1073 - MSE: 0.0224 - val_loss: 0.0963 - val_MSE: 0.0202\n",
            "Epoch 59/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1081 - MSE: 0.0227 - val_loss: 0.0970 - val_MSE: 0.0202\n",
            "Epoch 60/60\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1081 - MSE: 0.0226 - val_loss: 0.0912 - val_MSE: 0.0190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logra una mejora considerable en comparación a las anteriores, pero este primer modelo no consigue bajar más que el original. La ides es conseguir un loss inferior a 0.1080. Sin embargo, aumentar el número de épocas a 60 permite que alcanzar un loss de 0.1081."
      ],
      "metadata": {
        "id": "9eRhV6ysLVH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ARQUITECTURA DE RED NEURONAL\n",
        "  # añadir capa oculta con 4 neuronas\n",
        "  # añadir segunda capa de flatten\n",
        "  # usar optimizador Adam\n",
        "\n",
        "\n",
        "def crear_modeloEmbeddings():\n",
        "    emb_dias = 2 #tamaño profundidad de embeddings\n",
        "    emb_meses = 4\n",
        "\n",
        "    in_dias = Input(shape=[1], name = 'dias')\n",
        "    emb_dias = Embedding(7+1, emb_dias)(in_dias)\n",
        "    in_meses = Input(shape=[1], name = 'meses')\n",
        "    emb_meses = Embedding(12+1, emb_meses)(in_meses)\n",
        "\n",
        "    in_cli = Input(shape=[PASOS], name = 'cli')\n",
        "\n",
        "    fe = concatenate([(emb_dias), (emb_meses)])\n",
        "\n",
        "    x = Flatten()(fe)\n",
        "    x = Dense(PASOS,activation='tanh')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(6,activation='tanh')(x)\n",
        "    outp = Dense(1,activation='tanh')(x)\n",
        "    model = Model(inputs=[in_dias,in_meses,in_cli], outputs=outp)\n",
        "\n",
        "    model.compile(loss='mean_absolute_error', \n",
        "                  optimizer='adam',\n",
        "                  metrics=['MSE'])\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "NIypX7siLjJj"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ENTRENAMIENTO \n",
        "\n",
        "EPOCHS=80\n",
        "\n",
        "model = crear_modeloEmbeddings()\n",
        "\n",
        "continuas=training_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
        "valid_continuas=valid_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
        "\n",
        "history=model.fit([training_data['weekday'],training_data['month'],continuas], target_data, epochs=EPOCHS\n",
        "                 ,validation_data=([valid_data['weekday'],valid_data['month'],valid_continuas],valid_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njcxhNo7MazT",
        "outputId": "72b5167e-7617-4cc2-c001-e98c6d6647e9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " dias (InputLayer)              [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " meses (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_30 (Embedding)       (None, 1, 2)         16          ['dias[0][0]']                   \n",
            "                                                                                                  \n",
            " embedding_31 (Embedding)       (None, 1, 4)         52          ['meses[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 1, 6)         0           ['embedding_30[0][0]',           \n",
            "                                                                  'embedding_31[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_24 (Flatten)           (None, 6)            0           ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            " dense_70 (Dense)               (None, 7)            49          ['flatten_24[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_25 (Flatten)           (None, 7)            0           ['dense_70[0][0]']               \n",
            "                                                                                                  \n",
            " dense_71 (Dense)               (None, 6)            48          ['flatten_25[0][0]']             \n",
            "                                                                                                  \n",
            " cli (InputLayer)               [(None, 7)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_72 (Dense)               (None, 1)            7           ['dense_71[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 172\n",
            "Trainable params: 172\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/80\n",
            "19/19 [==============================] - 1s 13ms/step - loss: 0.3719 - MSE: 0.1858 - val_loss: 0.3789 - val_MSE: 0.1854\n",
            "Epoch 2/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2660 - MSE: 0.1069 - val_loss: 0.2446 - val_MSE: 0.0912\n",
            "Epoch 3/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1977 - MSE: 0.0640 - val_loss: 0.1600 - val_MSE: 0.0478\n",
            "Epoch 4/80\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1726 - MSE: 0.0508 - val_loss: 0.1434 - val_MSE: 0.0392\n",
            "Epoch 5/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1545 - MSE: 0.0415 - val_loss: 0.1328 - val_MSE: 0.0337\n",
            "Epoch 6/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1390 - MSE: 0.0333 - val_loss: 0.1191 - val_MSE: 0.0279\n",
            "Epoch 7/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1269 - MSE: 0.0281 - val_loss: 0.1080 - val_MSE: 0.0237\n",
            "Epoch 8/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1182 - MSE: 0.0251 - val_loss: 0.1041 - val_MSE: 0.0221\n",
            "Epoch 9/80\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1129 - MSE: 0.0236 - val_loss: 0.0975 - val_MSE: 0.0206\n",
            "Epoch 10/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1101 - MSE: 0.0227 - val_loss: 0.0946 - val_MSE: 0.0198\n",
            "Epoch 11/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1091 - MSE: 0.0226 - val_loss: 0.0943 - val_MSE: 0.0198\n",
            "Epoch 12/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1086 - MSE: 0.0224 - val_loss: 0.0962 - val_MSE: 0.0203\n",
            "Epoch 13/80\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1089 - MSE: 0.0225 - val_loss: 0.0925 - val_MSE: 0.0194\n",
            "Epoch 14/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1089 - MSE: 0.0225 - val_loss: 0.0973 - val_MSE: 0.0202\n",
            "Epoch 15/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1087 - MSE: 0.0226 - val_loss: 0.0954 - val_MSE: 0.0201\n",
            "Epoch 16/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - MSE: 0.0223 - val_loss: 0.0947 - val_MSE: 0.0198\n",
            "Epoch 17/80\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1087 - MSE: 0.0224 - val_loss: 0.0955 - val_MSE: 0.0200\n",
            "Epoch 18/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1089 - MSE: 0.0227 - val_loss: 0.0975 - val_MSE: 0.0203\n",
            "Epoch 19/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1091 - MSE: 0.0224 - val_loss: 0.0948 - val_MSE: 0.0197\n",
            "Epoch 20/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1086 - MSE: 0.0225 - val_loss: 0.0975 - val_MSE: 0.0204\n",
            "Epoch 21/80\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1085 - MSE: 0.0224 - val_loss: 0.0936 - val_MSE: 0.0195\n",
            "Epoch 22/80\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1083 - MSE: 0.0224 - val_loss: 0.0970 - val_MSE: 0.0205\n",
            "Epoch 23/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1082 - MSE: 0.0223 - val_loss: 0.0958 - val_MSE: 0.0200\n",
            "Epoch 24/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - MSE: 0.0223 - val_loss: 0.0935 - val_MSE: 0.0196\n",
            "Epoch 25/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1094 - MSE: 0.0226 - val_loss: 0.0966 - val_MSE: 0.0199\n",
            "Epoch 26/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1089 - MSE: 0.0229 - val_loss: 0.0949 - val_MSE: 0.0198\n",
            "Epoch 27/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0224 - val_loss: 0.0954 - val_MSE: 0.0198\n",
            "Epoch 28/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - MSE: 0.0225 - val_loss: 0.0947 - val_MSE: 0.0197\n",
            "Epoch 29/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0955 - val_MSE: 0.0200\n",
            "Epoch 30/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1080 - MSE: 0.0224 - val_loss: 0.0960 - val_MSE: 0.0202\n",
            "Epoch 31/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0951 - val_MSE: 0.0196\n",
            "Epoch 32/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1085 - MSE: 0.0225 - val_loss: 0.0957 - val_MSE: 0.0200\n",
            "Epoch 33/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0964 - val_MSE: 0.0202\n",
            "Epoch 34/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0968 - val_MSE: 0.0203\n",
            "Epoch 35/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1085 - MSE: 0.0224 - val_loss: 0.0927 - val_MSE: 0.0192\n",
            "Epoch 36/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1086 - MSE: 0.0224 - val_loss: 0.0956 - val_MSE: 0.0200\n",
            "Epoch 37/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1081 - MSE: 0.0225 - val_loss: 0.0964 - val_MSE: 0.0202\n",
            "Epoch 38/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1081 - MSE: 0.0225 - val_loss: 0.0933 - val_MSE: 0.0194\n",
            "Epoch 39/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0952 - val_MSE: 0.0198\n",
            "Epoch 40/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - MSE: 0.0224 - val_loss: 0.0965 - val_MSE: 0.0201\n",
            "Epoch 41/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1084 - MSE: 0.0226 - val_loss: 0.0970 - val_MSE: 0.0203\n",
            "Epoch 42/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0979 - val_MSE: 0.0204\n",
            "Epoch 43/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1091 - MSE: 0.0225 - val_loss: 0.0953 - val_MSE: 0.0198\n",
            "Epoch 44/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1081 - MSE: 0.0223 - val_loss: 0.0944 - val_MSE: 0.0198\n",
            "Epoch 45/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0225 - val_loss: 0.0986 - val_MSE: 0.0206\n",
            "Epoch 46/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1086 - MSE: 0.0223 - val_loss: 0.0939 - val_MSE: 0.0196\n",
            "Epoch 47/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1081 - MSE: 0.0223 - val_loss: 0.0967 - val_MSE: 0.0204\n",
            "Epoch 48/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1087 - MSE: 0.0223 - val_loss: 0.0926 - val_MSE: 0.0191\n",
            "Epoch 49/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1089 - MSE: 0.0226 - val_loss: 0.0992 - val_MSE: 0.0205\n",
            "Epoch 50/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1106 - MSE: 0.0233 - val_loss: 0.0953 - val_MSE: 0.0194\n",
            "Epoch 51/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1091 - MSE: 0.0225 - val_loss: 0.0929 - val_MSE: 0.0194\n",
            "Epoch 52/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1094 - MSE: 0.0227 - val_loss: 0.0943 - val_MSE: 0.0196\n",
            "Epoch 53/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0225 - val_loss: 0.0956 - val_MSE: 0.0199\n",
            "Epoch 54/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1080 - MSE: 0.0222 - val_loss: 0.0945 - val_MSE: 0.0195\n",
            "Epoch 55/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0225 - val_loss: 0.0958 - val_MSE: 0.0201\n",
            "Epoch 56/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1081 - MSE: 0.0223 - val_loss: 0.0930 - val_MSE: 0.0194\n",
            "Epoch 57/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1087 - MSE: 0.0226 - val_loss: 0.0974 - val_MSE: 0.0202\n",
            "Epoch 58/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1080 - MSE: 0.0223 - val_loss: 0.0961 - val_MSE: 0.0198\n",
            "Epoch 59/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1080 - MSE: 0.0224 - val_loss: 0.0967 - val_MSE: 0.0200\n",
            "Epoch 60/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1085 - MSE: 0.0228 - val_loss: 0.0951 - val_MSE: 0.0198\n",
            "Epoch 61/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1084 - MSE: 0.0224 - val_loss: 0.0943 - val_MSE: 0.0197\n",
            "Epoch 62/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0225 - val_loss: 0.0962 - val_MSE: 0.0201\n",
            "Epoch 63/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1080 - MSE: 0.0223 - val_loss: 0.0932 - val_MSE: 0.0193\n",
            "Epoch 64/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1085 - MSE: 0.0225 - val_loss: 0.0982 - val_MSE: 0.0205\n",
            "Epoch 65/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1077 - MSE: 0.0224 - val_loss: 0.0933 - val_MSE: 0.0197\n",
            "Epoch 66/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1086 - MSE: 0.0226 - val_loss: 0.0954 - val_MSE: 0.0201\n",
            "Epoch 67/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1078 - MSE: 0.0223 - val_loss: 0.0933 - val_MSE: 0.0198\n",
            "Epoch 68/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1081 - MSE: 0.0225 - val_loss: 0.0961 - val_MSE: 0.0202\n",
            "Epoch 69/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1081 - MSE: 0.0223 - val_loss: 0.0917 - val_MSE: 0.0191\n",
            "Epoch 70/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1085 - MSE: 0.0225 - val_loss: 0.0969 - val_MSE: 0.0202\n",
            "Epoch 71/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - MSE: 0.0225 - val_loss: 0.0956 - val_MSE: 0.0199\n",
            "Epoch 72/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0225 - val_loss: 0.0944 - val_MSE: 0.0197\n",
            "Epoch 73/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0972 - val_MSE: 0.0203\n",
            "Epoch 74/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0223 - val_loss: 0.0931 - val_MSE: 0.0194\n",
            "Epoch 75/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1080 - MSE: 0.0224 - val_loss: 0.0989 - val_MSE: 0.0208\n",
            "Epoch 76/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1082 - MSE: 0.0224 - val_loss: 0.0948 - val_MSE: 0.0199\n",
            "Epoch 77/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1079 - MSE: 0.0224 - val_loss: 0.0947 - val_MSE: 0.0198\n",
            "Epoch 78/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1089 - MSE: 0.0226 - val_loss: 0.0950 - val_MSE: 0.0200\n",
            "Epoch 79/80\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1087 - MSE: 0.0227 - val_loss: 0.0953 - val_MSE: 0.0198\n",
            "Epoch 80/80\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1083 - MSE: 0.0225 - val_loss: 0.0988 - val_MSE: 0.0205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "He probado con el cambio de varios parámetros pero no logro mejorar el rendimiento del origunal. Al menos tampoco empeorarlo, ¡no es mala señal!"
      ],
      "metadata": {
        "id": "r8Uum8fIsg0v"
      }
    }
  ]
}